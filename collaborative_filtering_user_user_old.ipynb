{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrado colaborativo usuario a usuario\n",
    "\n",
    "**Autor**: Arturo Sánchez Palacio\n",
    "\n",
    "Basado en: https://github.com/lazyprogrammer\n",
    "\n",
    "**Fecha de última revisión: 16/I/2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook se emplearán los siguientes módulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos cargando los datos almacenados en los diccionarios generados en el preprocesamiento:\n",
    "\n",
    "__Nota.__ Si el notebook de preprocesamiento no se ha ejecutado antes debe ejecutarse ahora para generar los datos con los que se trabaja en este notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/usuario_pelicula.json', 'rb') as f:\n",
    "  usuario_pelicula = pickle.load(f)\n",
    "\n",
    "with open('./data/pelicula_usuario.json', 'rb') as f:\n",
    "  pelicula_usuario = pickle.load(f)\n",
    "\n",
    "with open('./data/usuariopeli_rating.json', 'rb') as f:\n",
    "  usuariopeli_rating = pickle.load(f)\n",
    "\n",
    "with open('./data/usuariopeli_rating_test.json', 'rb') as f:\n",
    "  usuariopeli_rating_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo vamos a cálcular N y M como el número máximo de usuarios películas. Esta vez es algo más complicado pues puede haber películas que no aparezcan en el training set pero sí en el test set. Esto mismo es muy improbable para usuarios por lo que N se puede calcular de manera trivial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do. Calcular el número de usuarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular M buscamos el máximo tanto en pelicula_usuario como en usuariopeli_rating_test y fijamos como M el máximo de ambas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do calcular el número de películas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí reflexionamos de nuevo sobre el coste computacional de la operación. Recordemos que el algoritmo es  $O(N^2 * M)$ así que para valores de N muy altos deberíamos plantearnos volver a muestrear. 10.000 es elevado pero está bien así que pododemos continuar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nota.__ Recordemos las fórmulas que definen los pesos y las predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/pesos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/predicciones.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como discutimos previamente en la explicación teórica fijamos el número de vecinos máximo que vamos a considerar y un umbral de películas comunes (no calcularemos pesos para usuarios que tengan menos películas en común que este umbral). Fijamos explorar 25 vecinos (como máximo) y un umbral de al menos cinco películas en común con el usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 25 #número máximo de vecinos\n",
    "umbral = 5 #número mínimo de películas comunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos tres listas vacías en las que almacenaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecinos = [] #vecinos para el usuario\n",
    "medias = [] # valoración media de cada usuario\n",
    "desviaciones = [] #desviaciones de cada usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedList\n",
    "for i in range(N):\n",
    "    #buscamos los K usuarios más próximos a i\n",
    "    peliculas_i = usuario_pelicula[i] #pelis que el usuario ha visto\n",
    "    peliculas_i_set = set(peliculas_i) #las almaceno en un conjunto\n",
    "    ratings_i = { pelicula:usuariopeli_rating[(i, pelicula)] for pelicula in peliculas_i } #construyo un diccionario de clave película y valor sus puntaciones\n",
    "    avg_i = np.mean(list(ratings_i.values())) #puntuación media del usuario i\n",
    "    dev_i = {pelicula:(rating - avg_i) for pelicula, rating in ratings_i.items()} #desviaciones del usuario i\n",
    "    dev_i_values = np.array(list(dev_i.values())) #array de Numpy con las desviaciones\n",
    "    sigma_i = np.sqrt(dev_i_values.dot(dev_i_values)) #denominador del coeficiente de Pearson\n",
    "\n",
    "    medias.append(avg_i) #guardo las medias para usarlas en un futuro\n",
    "    desviaciones.append(dev_i) #guardo las desviaciones para usarlas en un futuro\n",
    "\n",
    "    sl = SortedList() #Creo una lista ordenada en la que almacenar los pesos que ya tengo calculados (mantengo las 25 entradas que nos interesan)\n",
    "                         \n",
    "    for j in range(N): #Para cada usuario distinto de i calculo el peso i j (no es eficiente computacionalmente pero costaría más memoria optimizarlo)\n",
    "    \n",
    "        if j != i: #el propio usuario no puede ser su propio vecino\n",
    "            peliculas_j = usuario_pelicula[j]\n",
    "            peliculas_j_set = set(peliculas_j)\n",
    "            peliculas_comunes = (peliculas_i_set & peliculas_j_set) # peliculas comunes entre i y j (intersección)\n",
    "            if len(peliculas_comunes) > umbral: #solo calculamos el peso si son suficientemente similares\n",
    "        \n",
    "                ratings_j = { pelicula:usuariopeli_rating[(j, pelicula)] for pelicula in peliculas_j } #diccionario\n",
    "                avg_j = np.mean(list(ratings_j.values())) #puntuación media\n",
    "                dev_j = { pelicula:(rating - avg_j) for pelicula, rating in ratings_j.items() } #desviaciones\n",
    "                dev_j_values = np.array(list(dev_j.values())) #array de Numpy con las desviaciones\n",
    "                sigma_j = np.sqrt(dev_j_values.dot(dev_j_values)) #denominador del coeficiente de Pearson\n",
    "\n",
    "                # calculate correlation coefficient\n",
    "                numerador = sum(dev_i[m]*dev_j[m] for m in peliculas_comunes)\n",
    "                w_ij = numerador / (sigma_i * sigma_j)\n",
    "\n",
    "                sl.add((-w_ij, j)) #añadimos el peso y el usuario a la lista ordenada (- porque ordena ascendentemente)\n",
    "                if len(sl) > K: # Si la lista supera el límite de vecinos eliminamos el peso menos importante\n",
    "                    del sl[-1]\n",
    "\n",
    "    \n",
    "    vecinos.append(sl) #almacenamos los vecinos (usuario 0 en posición 0...)\n",
    "    print(i,\"/\",N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación construimos una función para calcular las predicciones. Partiendo de un usuario i y una película m predice la puntuación que este usuario daría a la película:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(i, m):\n",
    "   \n",
    "    numerador = 0 #suma del producto de los pesos y las desviaciones\n",
    "    denominador = 0 #suma de los valores absolutos de los pesos\n",
    "    for vecino in vecinos[i]:\n",
    "        neg_w =vecino[0]\n",
    "        j = vecino[1]\n",
    "        desviaciones_j = desviaciones[j]\n",
    "        try:\n",
    "        # Si el vecino ha valorado la película calculamos:\n",
    "        ###EJERCICIO EMPIEZA\n",
    "            numerador +=  #Recordar que almacenamos el peso en negativo\n",
    "            denominador += \n",
    "        ###EJERCICIO ACABA\n",
    "        except KeyError:\n",
    "        #El vecino puede no haber valorado la película que predecimos.\n",
    "        #Lanzaremos una excepción cuando buscamos en el diccionario y no encontramos la valoración.\n",
    "            pass\n",
    "\n",
    "    if denominador == 0:\n",
    "        prediccion = medias[i] #No podemos hacer nada mejor que esto\n",
    "    else:\n",
    "        prediccion = numerador / denominador + medias[i]\n",
    "    ###EJERCICIO EMPIEZA\n",
    "     # la fórmula no está acotada así que la acotamos manualmente (esto es peligroso)\n",
    "     # la fórmula no está acotada así que la acotamos manualmente (esto es peligroso)\n",
    "    ###EJERCICIO ACABA\n",
    "    return prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dos listas para almacenar las predicciones y etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = []\n",
    "etiquetas_train = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do. Realizamos las predicciones para cada película y usuario en entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, m), etiqueta in usuariopeli_rating.items():\n",
    "     #Calculamos la predicción para la película\n",
    "\n",
    "    # Almacenamos la predicción y la etiqueta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do. Análogamente en el test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do. Implementamos una función trivial para calcular el error medio cuadrático:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(p, t):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar el error final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train mse:', mse(predicciones_train, etiquetas_train))\n",
    "print('test mse:', mse(predicciones_test, etiquetas_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Para ser una aproximación tan naïve los resultados no son nada despreciables. Es poco eficaz computacionalmente como hemos podido observar. Sin embargo es interesante comparar este resultado con los que obtendremos más adelante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
