{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorización matricial con Keras\n",
    "\n",
    "**Autor**: Arturo Sánchez Palacio\n",
    "\n",
    "Basado en: https://github.com/lazyprogrammer\n",
    "\n",
    "**Fecha de última revisión: 17/I/2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre comenzamos instalando los módulos que necesitamos e importándolos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras está optimizado para trabajar con enormes tamaños de datos por lo que en este caso trabajaremos con la base de datos __completa__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/preprocessed_rating.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el número total de usuarios y películas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df.userId.max() + 1\n",
    "M = df.movie_idx.max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es habitual en los procesos de Machine Learning dividimos en entrenamiento y test. En este caso fijamos el tamaño de entrenamiento al 80%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "umbral = int(0.8*len(df))\n",
    "df_train = df.iloc[:umbral]\n",
    "df_test = df.iloc[umbral:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos las variables habituales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10 # dimension latente\n",
    "mu = df_train.rating.mean() #media global\n",
    "iteraciones = 15 \n",
    "reg = 0. # coeficiente de regularización: ajuste de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos fijado las bases para construir el modelo. Importamos los tipos de capas que vamos a usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dot, Add, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos creando las capas de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wflop\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\wflop\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u = Input(shape=(1,)) # escalar del usuario\n",
    "m = Input(shape=(1,)) # escalar de la película"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el embedding con la regularización del vector de usuario y de película en las matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wflop\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "u_embedding = Embedding(N, K, embeddings_regularizer=l2(reg))(u) # dimensión: (N, 1, K)\n",
    "m_embedding = Embedding(M, K, embeddings_regularizer=l2(reg))(m) # dimensión: (N, 1, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez introducidos la película y el usuario introducimos el sesgo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_bias = Embedding(N, 1, embeddings_regularizer=l2(reg))(u) # dimensión: (N, 1, 1)\n",
    "m_bias = Embedding(M, 1, embeddings_regularizer=l2(reg))(m) # dimensión: (N, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el producto del embedding de los usuarios y las películas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dot(axes=2)([u_embedding, m_embedding]) # (N, 1, 1)\n",
    "#Aquí no hay aprediaje, solo un producto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumamos al resultado anterior los sesgos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Add()([x, u_bias, m_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos una capa `Flatten` para garantizar que la salida es 1 x 1. Recordemos que buscamos el score de la recomendación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(x) # (N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la estructura final del modelo. Instanciamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model = Model(inputs=[u, m], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wflop\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "model.compile(\n",
    "  loss='mse',#usamos como función de pérdida el error medio cuadrático\n",
    "  optimizer=SGD(lr=0.08, momentum=0.9), #usamos como optimizador SGD con learning rate 0.08 y momentum 0.9\n",
    "  metrics=['mse'], #empleamos como métric a el error medio cuadrático\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el modelo construido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 10)        1384930     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 10)        267440      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 1)         138493      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 1)         26744       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1, 1)         0           dot_1[0][0]                      \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,817,607\n",
      "Trainable params: 1,817,607\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo ya está listo para ser entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wflop\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\wflop\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 16000210 samples, validate on 4000053 samples\n",
      "Epoch 1/15\n",
      " 4842240/16000210 [========>.....................] - ETA: 11:36 - loss: 0.8317 - mean_squared_error: 0.8317"
     ]
    }
   ],
   "source": [
    "#A partir solamente de los identificadores se obtienen los ratings.\n",
    "r = model.fit(\n",
    "  x=[df_train.userId.values, df_train.movie_idx.values], #variables de entrada\n",
    "  y=df_train.rating.values - mu, #etiquetas a predecir\n",
    "  epochs=iteraciones,\n",
    "  batch_size=128, #tamaño del batch\n",
    "  validation_data=([df_test.userId.values, df_test.movie_idx.values],  df_test.rating.values - mu) #datos de validacion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto r almacena en su historia las pérdidas a lo largo del entrenamiento y podemos tanto observarlas como representarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(r.history['loss'], label=\"Pérdida entrenamiento\")\n",
    "plt.plot(r.history['val_loss'], label=\"Pérdida validación\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot mse\n",
    "plt.plot(r.history['mse'], label=\"Error medio cuadrático (entrenamiento)\")\n",
    "plt.plot(r.history['val_mse'], label=\"Erros medio cuadrático (test)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "La parte más interesante de este modelo es que al ser mucho más rápido nos permite entrenar con todos los datos en lugar de la muestra. La manera de construir el modelo además es mucho más sencilla y escalable. En cuanto a resultados podemos observar que las pérdidas con una red bastante sencilla son asimilables a lo visto hasta ahora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
